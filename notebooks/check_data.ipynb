{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/hieutt/UniCon_EnetV2_OpenMax/notebooks', '/home/hieutt/miniconda3/envs/torchtf/lib/python39.zip', '/home/hieutt/miniconda3/envs/torchtf/lib/python3.9', '/home/hieutt/miniconda3/envs/torchtf/lib/python3.9/lib-dynload', '', '/home/hieutt/miniconda3/envs/torchtf/lib/python3.9/site-packages', '../']\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record 1 - Timestamp data:\n",
      "[[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
      "  1 1 1 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0]\n",
      " [0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1\n",
      "  0 1 1 0 0 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1]\n",
      " [1 0 0 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1\n",
      "  1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      "  1 1 1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
      "  1 1 1 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0]\n",
      " [1 0 0 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1\n",
      "  1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0]\n",
      " [1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      "  1 1 0 0 0 1 1 1 1 1 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      "  0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
      "  1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 0 1 0]\n",
      " [1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0\n",
      "  0 0 1 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 1 1 0 0 0 1 0 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 1 1 1 0 1 0 0\n",
      "  0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1]\n",
      " [0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 1 0 1 0\n",
      "  1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0]\n",
      " [1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0]\n",
      " [0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0\n",
      "  0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0]\n",
      " [1 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 1\n",
      "  1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1]\n",
      " [0 1 0 1 0 1 1 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 1 1 0 0 1 0 1 0 1 0 0 1 1 0\n",
      "  0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 1\n",
      "  0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 1]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 0 0\n",
      "  0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1]\n",
      " [0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0]\n",
      " [0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 1 1 1 0 0 1 1 0 0 0 0 1 0 1 0 0 1 1 0 0 0\n",
      "  1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0\n",
      "  0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0]\n",
      " [1 0 0 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 1 0\n",
      "  0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [1 0 0 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 1 0\n",
      "  0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0]\n",
      " [0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 1 1 1 0 0 1 1 0 0 0 0 1 0 1 0 0 1 1 0 0 0\n",
      "  1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0\n",
      "  1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0\n",
      "  1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1]\n",
      " [0 0 0 0 1 0 1 1 0 0 0 1 1 1 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0\n",
      "  0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1]\n",
      " [0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 0 1 0\n",
      "  1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 1 1 0 0 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0\n",
      "  0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 1 1\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 1 1 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 1 0 1 0 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1\n",
      "  1 1 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1]\n",
      " [0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1\n",
      "  0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 1]\n",
      " [1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1\n",
      "  1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1]\n",
      " [0 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0\n",
      "  0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 0 1]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 1 0 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1\n",
      "  1 1 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1]\n",
      " [1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1\n",
      "  1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1]\n",
      " [1 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      "  1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [1 1 0 1 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      "  0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1\n",
      "  0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0\n",
      "  0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 0 1]]\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# /Users/hieutran/lab/unicon-ids/data/can-ml/preprocessed/all_features/TFRecord_w32_s16/2\n",
    "tfrecord_file_path = '../data/can-ml/2017-subaru-forester/preprocessed/size_64_10/TFRecord_w64_s32/2/train/0.tfrec'\n",
    "def parse_tfrecord_fn(example):\n",
    "    feature_description = {\n",
    "        'id_seq': tf.io.FixedLenFeature([64, 64], tf.int64),\n",
    "        'data_seq': tf.io.FixedLenFeature([64, 64], tf.int64),\n",
    "        'timestamp': tf.io.FixedLenFeature([64, 64], tf.float32),\n",
    "        'label': tf.io.FixedLenFeature([1], tf.int64)\n",
    "    }\n",
    "    return tf.io.parse_single_example(example, feature_description)\n",
    "\n",
    "# Tạo dataset từ TFRecord file\n",
    "raw_dataset = tf.data.TFRecordDataset(tfrecord_file_path)\n",
    "parsed_dataset = raw_dataset.map(parse_tfrecord_fn)\n",
    "\n",
    "# Hiển thị toàn bộ nội dung của timestamp\n",
    "for i, parsed_record in enumerate(parsed_dataset.take(5)):  # Lấy 5 bản ghi đầu tiên\n",
    "    timestamp_array = parsed_record['data_seq'].numpy()  # Chuyển sang NumPy array\n",
    "    print(f\"Record {i+1} - Timestamp data:\")\n",
    "    print(np.array2string(timestamp_array, threshold=np.inf))  # In toàn bộ dữ liệu\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang chạy trên: cuda\n",
      "Thời gian suy luận trung bình cho một frame 64 messages: 23.33 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from networks.efficient_net import ConEfficientNet\n",
    "# Chọn thiết bị chạy thử nghiệm (GPU nếu có)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Đang chạy trên: {device}\")\n",
    "\n",
    "# Tạo batch giả lập (1 ảnh 64x64)\n",
    "test_input = torch.randn(1, 3, 64, 64).to(device)\n",
    "\n",
    "# Khởi tạo mô hình và chuyển sang thiết bị thích hợp\n",
    "model = ConEfficientNet(embedding_dim=1792, feat_dim=128, head='mlp', pretrained=False).to(device)\n",
    "model.eval()\n",
    "\n",
    "# Đo thời gian inference 100 lần để lấy trung bình\n",
    "num_trials = 100\n",
    "timing_results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(num_trials):\n",
    "        torch.cuda.synchronize() if torch.cuda.is_available() else None  # Đồng bộ hóa GPU nếu cần\n",
    "        start_time = time.time()\n",
    "        _ = model(test_input)  # Chạy mô hình\n",
    "        torch.cuda.synchronize() if torch.cuda.is_available() else None  # Đồng bộ hóa GPU nếu cần\n",
    "        end_time = time.time()\n",
    "        timing_results.append((end_time - start_time) * 1000)  # Chuyển sang milliseconds\n",
    "\n",
    "# Tính trung bình thời gian inference\n",
    "avg_inference_time = sum(timing_results) / num_trials\n",
    "\n",
    "print(f\"Thời gian suy luận trung bình cho một frame 64 messages: {avg_inference_time:.2f} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang chạy trên thiết bị: cuda\n",
      "Thời gian suy luận trung bình (EfficientNet-B0 Pruned): 6.88 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from networks.efficient_net_lite import ConEfficientNet\n",
    "# Chọn thiết bị\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Đang chạy trên thiết bị: {device}\")\n",
    "\n",
    "# Tạo batch input giả lập\n",
    "test_input = torch.randn(1, 3, 64, 64).to(device)\n",
    "\n",
    "# Khởi tạo mô hình EfficientNet-B0 Pruned\n",
    "model = ConEfficientNet(embedding_dim=1024, feat_dim=128, head='mlp', pretrained=False).to(device)\n",
    "model.eval()\n",
    "\n",
    "# Đo thời gian inference 100 lần\n",
    "num_trials = 100\n",
    "timing_results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(num_trials):\n",
    "        torch.cuda.synchronize() if torch.cuda.is_available() else None  # Đồng bộ hóa GPU nếu cần\n",
    "        start_time = time.time()\n",
    "        _ = model(test_input)\n",
    "        torch.cuda.synchronize() if torch.cuda.is_available() else None  # Đồng bộ hóa GPU nếu cần\n",
    "        end_time = time.time()\n",
    "        timing_results.append((end_time - start_time) * 1000)  # ms\n",
    "\n",
    "# Kết quả\n",
    "avg_inference_time = sum(timing_results) / num_trials\n",
    "print(f\"Thời gian suy luận trung bình (EfficientNet-B0 Pruned): {avg_inference_time:.2f} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang chạy trên thiết bị: cuda\n"
     ]
    }
   ],
   "source": [
    "from networks.efficient_net_lite import ConEfficientNet\n",
    "import torch\n",
    "# Chọn thiết bị\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Đang chạy trên thiết bị: {device}\")\n",
    "model = ConEfficientNet(embedding_dim=1280, feat_dim=128, head='mlp', pretrained=False).to(device)\n",
    "test_input = torch.randn(1, 3, 64, 64).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước đầu ra của mô hình: torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "output = model(test_input)\n",
    "print(\"Kích thước đầu ra của mô hình:\", output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d               | Input Shape: torch.Size([1, 3, 64, 64])     | Output Shape: torch.Size([1, 32, 64, 64])\n",
      "BatchNorm2d          | Input Shape: torch.Size([1, 32, 64, 64])    | Output Shape: torch.Size([1, 32, 64, 64])\n",
      "ReLU6                | Input Shape: torch.Size([1, 32, 64, 64])    | Output Shape: torch.Size([1, 32, 64, 64])\n",
      "Conv2dStaticSamePadding | Input Shape: torch.Size([1, 320, 4, 4])     | Output Shape: torch.Size([1, 1280, 4, 4])\n",
      "BatchNorm2d          | Input Shape: torch.Size([1, 1280, 4, 4])    | Output Shape: torch.Size([1, 1280, 4, 4])\n",
      "ReLU6                | Input Shape: torch.Size([1, 1280, 4, 4])    | Output Shape: torch.Size([1, 1280, 4, 4])\n",
      "Linear               | Input Shape: torch.Size([1, 1280])          | Output Shape: torch.Size([1, 1280])\n",
      "Linear               | Input Shape: torch.Size([1, 1280])          | Output Shape: torch.Size([1, 1280])\n"
     ]
    }
   ],
   "source": [
    "# Hàm hook để in ra kích thước đầu vào và đầu ra của từng lớp\n",
    "import torch.nn as nn\n",
    "def print_shapes_hook(module, input, output):\n",
    "    print(f\"{module.__class__.__name__.ljust(20)} | \"\n",
    "          f\"Input Shape: {str(input[0].shape).ljust(30)} | \"\n",
    "          f\"Output Shape: {str(output.shape)}\")\n",
    "\n",
    "for name, module in model.encoder._modules.items():\n",
    "    # Đối với các MBConv block, bạn sẽ cần đăng ký hook vào các lớp con của nó\n",
    "    if isinstance(module, nn.Module):\n",
    "        # Đăng ký hook vào tất cả các lớp con\n",
    "        for sub_name, sub_module in module.named_children():\n",
    "            sub_module.register_forward_hook(print_shapes_hook)\n",
    "\n",
    "\n",
    "# Tiến hành kiểm tra thông qua forward pass\n",
    "output = model(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_gan import Generator, Discriminator\n",
    "G = Generator()\n",
    "D = Discriminator()\n",
    "import torch\n",
    "z = torch.randn(4, 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Generator Output] shape: torch.Size([4, 8256]), norm: tensor([ 7.4615,  9.0911, 10.1059,  9.3146],\n",
      "       grad_fn=<LinalgVectorNormBackward0>), min: -0.5246, max: 0.4161\n"
     ]
    }
   ],
   "source": [
    "# Forward Generator\n",
    "gen_feat = G(z)\n",
    "print(f\"[Generator Output] shape: {gen_feat.shape}, norm: {gen_feat.norm(p=2, dim=1)}, min: {gen_feat.min().item():.4f}, max: {gen_feat.max().item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Discriminator Score] shape: torch.Size([4, 1]), values: [0.00765092670917511, 0.01895749941468239, 0.00991226639598608, 0.00663892924785614]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "score = D(gen_feat)\n",
    "print(f\"[Discriminator Score] shape: {score.shape}, values: {score.view(-1).tolist()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchtf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
