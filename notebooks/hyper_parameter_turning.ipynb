{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/hieutt/UniCon_EnetV2_OpenMax/notebooks', '/home/hieutt/miniconda3/envs/torchtf/lib/python39.zip', '/home/hieutt/miniconda3/envs/torchtf/lib/python3.9', '/home/hieutt/miniconda3/envs/torchtf/lib/python3.9/lib-dynload', '', '/home/hieutt/miniconda3/envs/torchtf/lib/python3.9/site-packages', '../']\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import pprint\n",
    "from torchvision import transforms\n",
    "from dataset import CANDatasetEnet as CANDataset\n",
    "from losses import SupConLoss, UniConLoss\n",
    "from networks.efficient_net import ConEfficientNet, LinearClassifier\n",
    "from networks.mpncovresnet import TinyMPNCOVResNet, mpncovresnet34tiny\n",
    "from networks.efficient_net_b0 import ConEfficientNet as E_Unicon_B0, LinearClassifier as L_Unicon_B0\n",
    "from util import TwoCropTransform, AverageMeter, AddGaussianNoise\n",
    "from util import warmup_learning_rate\n",
    "from util import get_universum\n",
    "from util import save_model ,load_checkpoint, accuracy\n",
    "# from networks.classifier import LinearClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "# Định nghĩa cấu trúc `Opt` với các trường cần thiết\n",
    "Opt = namedtuple('Opt', ['lamda', 'mix', 'device', 'data_folder', 'num_workers', 'batch_size'])\n",
    "\n",
    "# Tạo đối tượng opt\n",
    "opt = Opt(\n",
    "    lamda=0.5,\n",
    "    mix='mixup',\n",
    "    device='cuda',\n",
    "    data_folder='../data/can-ml/2017-subaru-forester/preprocessed/size_64_10/TFRecord_w64_s32/2',\n",
    "    num_workers=8,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "# Truy cập các tham số\n",
    "print(opt.lamda)\n",
    "print(opt.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm này sẽ lấy một subset nhỏ từ dataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "\n",
    "def get_subset_loader(dataset, subset_ratio=0.1, batch_size=32):\n",
    "    subset_size = int(len(dataset) * subset_ratio)  # Tính số lượng phần tử của subset\n",
    "    indices = torch.randperm(len(dataset)).tolist()[:subset_size]  # Chọn ngẫu nhiên các chỉ số\n",
    "    subset = Subset(dataset, indices)  # Tạo Subset từ dataset gốc\n",
    "    \n",
    "    # Tạo DataLoader từ subset\n",
    "    subset_loader = DataLoader(subset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)  # Chỉnh batch_size, num_workers theo yêu cầu\n",
    "    return subset_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_loader(opt, batch_size, subset_ratio=0.1):\n",
    "    mean = (0.5, 0.5, 0.5)\n",
    "    std = (0.5, 0.5, 0.5)\n",
    "    normalize = transforms.Normalize(mean=mean, std=std)\n",
    "    transform = transforms.Compose([normalize])\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomApply([AddGaussianNoise(0., 0.05)], p=0.5),\n",
    "        transforms.RandomErasing(p=0.3, scale=(0.02, 0.15)),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "    \n",
    "    # Khởi tạo dataset\n",
    "    train_dataset = CANDataset(root_dir=opt.data_folder, window_size=32, is_train=True, transform=TwoCropTransform(train_transform))\n",
    "    test_dataset = CANDataset(root_dir=opt.data_folder, window_size=32, is_train=False, transform=transform)\n",
    "\n",
    "    # Lấy subset nhỏ của dataset\n",
    "    train_loader = get_subset_loader(train_dataset, subset_ratio=subset_ratio, batch_size=batch_size)  \n",
    "    test_loader = get_subset_loader(test_dataset, subset_ratio=subset_ratio, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_predict(outputs):\n",
    "    _, pred = outputs.topk(1, 1, True, True)\n",
    "    pred = pred.t().cpu().numpy().squeeze(0)\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(train_loader, model, classifier, criterion, optimizer, epoch, opt):\n",
    "    model.eval()\n",
    "    classifier.train()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    accs = AverageMeter()\n",
    "\n",
    "    # Start the training loop\n",
    "    end = time.time()\n",
    "    for idx, (images, labels) in enumerate(train_loader):\n",
    "        images = images[0]\n",
    "        # if torch.cuda.is_available():\n",
    "        #     images = images.cuda(non_blocking=True)\n",
    "        #     labels = labels.cuda(non_blocking=True)\n",
    "        images = images.to(opt.device, non_blocking=True)\n",
    "        labels = labels.to(opt.device, non_blocking=True)\n",
    "        bsz = labels.size(0)  # Batch size\n",
    "\n",
    "        # Extract features from the pre-trained model in evaluation mode\n",
    "        with torch.no_grad():\n",
    "            features = model.encoder(images)\n",
    "\n",
    "        # Forward pass through the classifier\n",
    "        output = classifier(features.detach())\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(output, labels)\n",
    "        losses.update(loss.item(), bsz)\n",
    "\n",
    "        # Compute accuracy\n",
    "        acc = accuracy(output, labels, topk=(1,))\n",
    "        accs.update(acc[0].item(), bsz)\n",
    "\n",
    "        # Backward pass and optimization step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, classifier, criterion, opt):\n",
    "    model.eval()\n",
    "    classifier.eval()\n",
    "    \n",
    "    losses = AverageMeter()\n",
    "    total_pred = np.array([], dtype=int)\n",
    "    total_label = np.array([], dtype=int) \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader): \n",
    "            # if torch.cuda.is_available():\n",
    "            #     images = images.cuda(non_blocking=True)\n",
    "            #     labels = labels.cuda(non_blocking=True)\n",
    "            images = images.to(opt.device, non_blocking=True)\n",
    "            labels = labels.to(opt.device, non_blocking=True)\n",
    "            features = model.encoder(images)\n",
    "            outputs = classifier(features)\n",
    "\n",
    "            bsz = labels.size(0)\n",
    "            loss = criterion(outputs, labels)\n",
    "            losses.update(loss.item(), bsz)\n",
    "            \n",
    "            pred = get_predict(outputs)\n",
    "\n",
    "            if isinstance(pred, torch.Tensor):\n",
    "                pred = pred.cpu().numpy()\n",
    "            \n",
    "            if isinstance(labels, torch.Tensor):\n",
    "                labels = labels.cpu().numpy()\n",
    "\n",
    "            total_pred = np.concatenate((total_pred, pred), axis=0)\n",
    "            total_label = np.concatenate((total_label, labels), axis=0)\n",
    "    \n",
    "    acc = accuracy_score(total_label, total_pred)\n",
    "    acc = acc * 100\n",
    "    f1 = f1_score(total_label, total_pred, average='weighted')\n",
    "    \n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_state_dict(state_dict):\n",
    "    \"\"\"\n",
    "    Because state dict in distributed GPU is different\n",
    "    \"\"\"\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        k = k.replace(\"module.\", \"\")\n",
    "        new_state_dict[k] = v\n",
    "    return new_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ConEfficientNet(embedding_dim=1792, feat_dim=128, head='mlp', pretrained=False)\n",
    "# classifier = LinearClassifier(input_dim=1792, num_classes=10)\n",
    "\n",
    "model = E_Unicon_B0(embedding_dim=1280, feat_dim=128, head='mlp', pretrained=False)\n",
    "classifier = L_Unicon_B0(input_dim=1280, num_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save_path = '../save/CAN-ML_models/UniCon/UniCon_CAN-ML_efficient-net_lr_0.05_decay_0.0001_bsz_64_temp_0.07_mixup_lambda_0.5_trial_can_ml_con_enet_b4_64_cosine_warm'\n",
    "# ckpt_epoch = 158\n",
    "# # save_path = '../save/CAN-ML_models/UniCon/UniCon_CAN-ML_resnet50_lr_0.05_decay_0.0001_bsz_64_temp_0.07_mixup_lambda_0.5_trial_can_ml_uni_resnet_cosine_warm/'\n",
    "# # ckpt_epoch = 37\n",
    "# model_path = f'{save_path}/last.pth'\n",
    "# model_path = f'{save_path}/ckpt_epoch_{ckpt_epoch}.pth'\n",
    "# ckpt = torch.load(model_path, weights_only=False)\n",
    "# state_dict = ckpt['model']\n",
    "# state_dict = change_state_dict(state_dict)\n",
    "# model.load_state_dict(state_dict=state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "def train_encoder(train_loader, learning_rate, criterion, optimizer):\n",
    "  model.train()\n",
    "\n",
    "  for images, labels in train_loader:\n",
    "      image1, image2 = images[0], images[1]\n",
    "      images = torch.cat([image1, image2], dim=0)\n",
    "      images = images.to('cuda')\n",
    "      labels = labels.to('cuda')\n",
    "      bsz = labels.shape[0]\n",
    "\n",
    "      universum = get_universum(images, labels, opt)\n",
    "      uni_features = model(universum)\n",
    "\n",
    "      features = model(images)\n",
    "      f1, f2 = torch.split(features, [bsz, bsz], dim=0)\n",
    "      features = torch.cat([f1.unsqueeze(1), f2.unsqueeze(1)], dim=1)\n",
    "\n",
    "      loss = criterion(features, uni_features, labels)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def objective(trial):\n",
    "    # 1. Tối ưu các siêu tham số\n",
    "    torch.cuda.empty_cache()\n",
    "    # learning_rate = trial.suggest_float('learning_rate', 1e-5, 0.001, log=True)\n",
    "    # new_batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128, 256])\n",
    "    # learning_rate = 0.05  # Ví dụ, bạn muốn dùng giá trị này cho tất cả các trial\n",
    "    lr_list = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.1, step=0.01)\n",
    "\n",
    "    # Sử dụng Optuna để chọn batch_size\n",
    "    new_batch_size = 64\n",
    "    # learning_rate = lr_list[trial.number % len(lr_list)]\n",
    "\n",
    "    train_loader, val_loader = set_loader(opt, new_batch_size)\n",
    "\n",
    "    model.to(opt.device)\n",
    "    classifier.to(opt.device)\n",
    "    # model = nn.DataParallel(model, device_ids=[0, 1])  # Chạy trên 2 GPU\n",
    "    # classifier = nn.DataParallel(classifier, device_ids=[0, 1])  # Nếu classifier cũng cần\n",
    "    # 4. Loss và Optimizer (chỉ tối ưu classifier)\n",
    "    criterion = UniConLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-4)\n",
    "    criterion_classifier = torch.nn.CrossEntropyLoss()\n",
    "    optimizer_classifier = torch.optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9, weight_decay=0)\n",
    "\n",
    "    step = 0\n",
    "    for epoch in range(5):\n",
    "        train_encoder(train_loader, learning_rate, criterion, optimizer)\n",
    "        train_classifier(\n",
    "            train_loader, model, classifier, criterion_classifier, optimizer_classifier, epoch, opt\n",
    "        )\n",
    "        torch.cuda.empty_cache()\n",
    "    acc, f1 = validate(\n",
    "        val_loader, model, classifier, criterion_classifier, opt\n",
    "    )\n",
    "\n",
    "    print(f\"[Trial {trial.number}] acc: {acc:.2f}, f1: {f1} lr: {learning_rate}, batch: {new_batch_size}\")\n",
    "\n",
    "    return f1  # F1 để Optuna tối ưu\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storage=\"sqlite:///db.sqlite3\",  # Specify the storage URL here.\n",
    "# study_name=\"hyper-parameter\",  # Unique identifier of the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 15:18:52,696] A new study created in RDB with name: contrastive_lr_tuning\n",
      "100%|██████████| 41/41 [00:01<00:00, 20.54it/s]\n",
      "[I 2025-03-28 15:20:29,783] Trial 0 finished with value: 0.9103659079621567 and parameters: {'learning_rate': 0.01}. Best is trial 0 with value: 0.9103659079621567.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 0] acc: 89.85, f1: 0.9103659079621567 lr: 0.01, batch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:01<00:00, 20.60it/s]\n",
      "[I 2025-03-28 15:22:06,923] Trial 1 finished with value: 0.9226422139276705 and parameters: {'learning_rate': 0.01}. Best is trial 1 with value: 0.9226422139276705.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 1] acc: 91.76, f1: 0.9226422139276705 lr: 0.01, batch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 20.49it/s]\n",
      "[I 2025-03-28 15:23:44,218] Trial 2 finished with value: 0.870858266890132 and parameters: {'learning_rate': 0.09}. Best is trial 1 with value: 0.9226422139276705.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 2] acc: 87.64, f1: 0.870858266890132 lr: 0.09, batch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 20.40it/s]\n",
      "[I 2025-03-28 15:25:21,539] Trial 3 finished with value: 0.8813547204765986 and parameters: {'learning_rate': 0.05}. Best is trial 1 with value: 0.9226422139276705.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 3] acc: 87.29, f1: 0.8813547204765986 lr: 0.05, batch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:01<00:00, 20.55it/s]\n",
      "[I 2025-03-28 15:27:00,665] Trial 4 finished with value: 0.8972287255570714 and parameters: {'learning_rate': 0.09999999999999999}. Best is trial 1 with value: 0.9226422139276705.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 4] acc: 91.57, f1: 0.8972287255570714 lr: 0.09999999999999999, batch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:01<00:00, 20.87it/s]\n",
      "[I 2025-03-28 15:28:39,478] Trial 5 finished with value: 0.8815705643650511 and parameters: {'learning_rate': 0.09999999999999999}. Best is trial 1 with value: 0.9226422139276705.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 5] acc: 88.71, f1: 0.8815705643650511 lr: 0.09999999999999999, batch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:01<00:00, 20.57it/s]\n",
      "[I 2025-03-28 15:30:17,235] Trial 6 finished with value: 0.8952433949291946 and parameters: {'learning_rate': 0.06999999999999999}. Best is trial 1 with value: 0.9226422139276705.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 6] acc: 91.45, f1: 0.8952433949291946 lr: 0.06999999999999999, batch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 19.73it/s]\n",
      "[I 2025-03-28 15:31:56,049] Trial 7 finished with value: 0.8751029368389939 and parameters: {'learning_rate': 0.09999999999999999}. Best is trial 1 with value: 0.9226422139276705.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 7] acc: 87.22, f1: 0.8751029368389939 lr: 0.09999999999999999, batch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:01<00:00, 20.54it/s]\n",
      "[I 2025-03-28 15:33:33,833] Trial 8 finished with value: 0.9484647928792764 and parameters: {'learning_rate': 0.03}. Best is trial 8 with value: 0.9484647928792764.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 8] acc: 95.35, f1: 0.9484647928792764 lr: 0.03, batch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:01<00:00, 20.68it/s]\n",
      "[I 2025-03-28 15:35:11,791] Trial 9 finished with value: 0.908537655529208 and parameters: {'learning_rate': 0.06999999999999999}. Best is trial 8 with value: 0.9484647928792764.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 9] acc: 91.61, f1: 0.908537655529208 lr: 0.06999999999999999, batch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 19.64it/s]\n",
      "[I 2025-03-28 15:36:50,356] Trial 10 finished with value: 0.9237887727167737 and parameters: {'learning_rate': 0.03}. Best is trial 8 with value: 0.9484647928792764.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 10] acc: 93.74, f1: 0.9237887727167737 lr: 0.03, batch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:01<00:00, 20.57it/s]\n",
      "[I 2025-03-28 15:38:28,163] Trial 11 finished with value: 0.9299315774711767 and parameters: {'learning_rate': 0.03}. Best is trial 8 with value: 0.9484647928792764.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 11] acc: 92.83, f1: 0.9299315774711767 lr: 0.03, batch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:02<00:00, 20.46it/s]\n",
      "[I 2025-03-28 15:40:06,778] Trial 12 finished with value: 0.9437331324000178 and parameters: {'learning_rate': 0.03}. Best is trial 8 with value: 0.9484647928792764.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 12] acc: 94.73, f1: 0.9437331324000178 lr: 0.03, batch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:01<00:00, 20.51it/s]\n",
      "[I 2025-03-28 15:41:43,755] Trial 13 finished with value: 0.9437111550320172 and parameters: {'learning_rate': 0.03}. Best is trial 8 with value: 0.9484647928792764.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 13] acc: 94.51, f1: 0.9437111550320172 lr: 0.03, batch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:01<00:00, 20.55it/s]\n",
      "[I 2025-03-28 15:43:21,965] Trial 14 finished with value: 0.9390770667383981 and parameters: {'learning_rate': 0.05}. Best is trial 8 with value: 0.9484647928792764.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 14] acc: 94.93, f1: 0.9390770667383981 lr: 0.05, batch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:01<00:00, 20.81it/s]\n",
      "[I 2025-03-28 15:44:58,677] Trial 15 finished with value: 0.9276718383280971 and parameters: {'learning_rate': 0.04}. Best is trial 8 with value: 0.9484647928792764.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 15] acc: 93.25, f1: 0.9276718383280971 lr: 0.04, batch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:01<00:00, 20.62it/s]\n",
      "[I 2025-03-28 15:46:34,226] Trial 16 finished with value: 0.9524194428587214 and parameters: {'learning_rate': 0.02}. Best is trial 16 with value: 0.9524194428587214.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 16] acc: 95.88, f1: 0.9524194428587214 lr: 0.02, batch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:01<00:00, 20.78it/s]\n",
      "[I 2025-03-28 15:48:12,288] Trial 17 finished with value: 0.9625352669069512 and parameters: {'learning_rate': 0.02}. Best is trial 17 with value: 0.9625352669069512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 17] acc: 96.60, f1: 0.9625352669069512 lr: 0.02, batch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:01<00:00, 20.67it/s]\n",
      "[I 2025-03-28 15:49:50,049] Trial 18 finished with value: 0.9585203363414991 and parameters: {'learning_rate': 0.01}. Best is trial 17 with value: 0.9625352669069512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 18] acc: 96.49, f1: 0.9585203363414991 lr: 0.01, batch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:01<00:00, 20.61it/s]\n",
      "[I 2025-03-28 15:51:27,704] Trial 19 finished with value: 0.9584849368512746 and parameters: {'learning_rate': 0.01}. Best is trial 17 with value: 0.9625352669069512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 19] acc: 96.49, f1: 0.9584849368512746 lr: 0.01, batch: 64\n",
      "Best trial:\n",
      "  F1: 0.9625352669069512\n",
      "  Params: {'learning_rate': 0.02}\n"
     ]
    }
   ],
   "source": [
    "# Tạo một study và bắt đầu tối ưu hóa siêu tham số\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    study_name='contrastive_lr_tuning',\n",
    "    storage='sqlite:///optuna_lr_tuning.db',\n",
    "    load_if_exists=True  # tránh lỗi khi chạy lại\n",
    ")\n",
    "\n",
    "# Chạy tối ưu hóa với 100 lần thử nghiệm\n",
    "study.optimize(objective, n_trials=20)\n",
    "# In kết quả tối ưu hóa\n",
    "print(\"Best trial:\")\n",
    "print(f\"  F1: {study.best_trial.value}\")\n",
    "print(f\"  Params: {study.best_trial.params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchtf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
